# Llama Backend Changelog

## [1.0.0] - 2024-08-14
### Initial Release
- Llama.cpp integration
- Support for GGUF models
- Multi-platform binaries (macOS, Linux, Windows)
- Automatic model downloading
- OpenAI-compatible API
- Context size configuration
- Thread count optimization

### Supported Platforms
- macOS (Intel & Apple Silicon)
- Linux (AMD64, ARM64, 386)
- Windows (AMD64, 386, ARM64)

### Models Tested
- Llama 2 7B/13B/70B
- Llama 3 8B/70B
- Mistral 7B
- Mixtral 8x7B
- CodeLlama variants